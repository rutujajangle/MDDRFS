{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score\n",
    "from .image_classification.scratch_models import model_generator\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplolib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43285a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['densenet', \n",
    "        'resnet', \n",
    "        'xceptionnet', \n",
    "        'mobilenet', \n",
    "        'efficientnetv2s', \n",
    "        'efficientnetv2m', \n",
    "        'efficientnetv2l', \n",
    "        'efficientnetv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (256, 256, 3)\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'sparse'\n",
    "OPTIM_TYPE = 'adam'\n",
    "CLASSES = 25\n",
    "\n",
    "# Initialize Variables \n",
    "# TODO: change the paths\n",
    "TRAIN_IMG_DIR = os.path.join('data/train')\n",
    "VALID_IMG_DIR = os.path.join('data/validate')\n",
    "TEST_IMG_DIR = os.path.join('data/test')\n",
    "\n",
    "# Initialize Data Generators\n",
    "# Different Augmentations can also be applied on data\n",
    "# Image Augmentation to be integrated\n",
    "# Basic Preprocessing included as of now\n",
    "train_data_generator = ImageDataGenerator(rescale=1/255.)\n",
    "validation_data_generator = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "# Get Training, Testing and Validation Data\n",
    "train_data = train_data_generator.flow_from_directory(\n",
    "                        TRAIN_IMG_DIR,\n",
    "                        target_size=SHAPE[:2],\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        class_mode=CLASS_MODE)\n",
    "\n",
    "valid_data = validation_data_generator.flow_from_directory(\n",
    "                        VALID_IMG_DIR,\n",
    "                        target_size=SHAPE[:2],\n",
    "                        batch_size=BATCH_SIZE//2,\n",
    "                        class_mode=CLASS_MODE)\n",
    "\n",
    "print(\"Training Data Indices: \", train_data.class_indices)\n",
    "print(\"Validation Data Indices: \", valid_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curve(history):\n",
    "    # Check how loss & accuracy evolved\n",
    "    epoch_loss = history.history['loss']\n",
    "    epoch_val_loss = history.history['val_loss']\n",
    "    epoch_mae = history.history['acc']\n",
    "    epoch_val_mae = history.history['val_acc']\n",
    "\n",
    "    # Learning curve\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\n",
    "    plt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\n",
    "    plt.title('Loss on train & validation datasets over epochs')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train Accuracy')\n",
    "    plt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val Accuracy')\n",
    "    plt.title('Accuracy on train & validation datasets over epochs')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ea53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "def testing(TEST_IMG_DIR, MODEL_NAME):\n",
    "\n",
    "    # Load test data\n",
    "    test_data_generator = ImageDataGenerator(rescale=1/255.)\n",
    "    test_data = test_data_generator.flow_from_directory(\n",
    "                            TEST_IMG_DIR,\n",
    "                            target_size=SHAPE,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            class_mode=CLASS_MODE,\n",
    "                            shuffle=False\n",
    "                            )\n",
    "\n",
    "    print(\"Testing Data Indices: \", test_data.class_indices)\n",
    "\n",
    "    # Load model and calculate metrics\n",
    "    if os.path.exists(f'image_classification/Models/binary_classification/{MODEL_NAME}_model'):\n",
    "        model = load_model(f\"image_classification/Models/binary_classification/{MODEL_NAME}_model\")\n",
    "        print(f'Successfully loaded {MODEL_NAME}')\n",
    "\n",
    "        images = len(test_data)\n",
    "\n",
    "        # Prediction start time\n",
    "        start_time = time.time()\n",
    "        predictions = model.predict(x=test_data)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Convert predictions to disease classes\n",
    "        classes = []\n",
    "        for pred in predictions:\n",
    "            cls = list(pred).index(pred.max())\n",
    "            classes.append(cls)\n",
    "                \n",
    "        accuracy = accuracy_score(list(test_data.classes), classes)\n",
    "        \n",
    "        f1_global = f1_score(list(test_data.classes), classes, average=\"micro\")\n",
    "        f1_individual = f1_score(list(test_data.classes), classes, average=\"macro\")\n",
    "        \n",
    "        precision_global = precision_score(list(test_data.classes), classes, average=\"micro\")\n",
    "        precision_individual = precision_score(list(test_data.classes), classes, average=\"macro\")\n",
    "        \n",
    "        recall_global = recall_score(list(test_data.classes), classes, average=\"micro\")\n",
    "        recall_individual = recall_score(list(test_data.classes), classes, average=\"macro\")\n",
    "        \n",
    "        total_infer_time = (end_time-start_time)*1e3\n",
    "        \n",
    "        infer_time = ((end_time-start_time)/images)*1e3\n",
    "\n",
    "        print('Model Name: ', MODEL_NAME)\n",
    "        print('---------------------------------------------------')\n",
    "        print('Testing Scores: ')\n",
    "        print('---------------------------------------------------')\n",
    "        print('Classification Report')\n",
    "        print(classification_report(list(test_data.classes), classes))\n",
    "        print('---------------------------------------------------')\n",
    "        print('Accuracy: ', accuracy)\n",
    "        print('---------------------------------------------------')\n",
    "        print('F1 Score Global: ', f1_global)\n",
    "        print('---------------------------------------------------')\n",
    "        print('F1 Score Individual: ', f1_individual)\n",
    "        print('---------------------------------------------------')\n",
    "        print('Precision Global: ', precision_global)\n",
    "        print('---------------------------------------------------')\n",
    "        print('Precision Individual: ', precision_individual)\n",
    "        print('---------------------------------------------------')\n",
    "        print('Recall Global: ', recall_global\n",
    "        print('---------------------------------------------------')\n",
    "        print('Recall Individual: ', recall_individual\n",
    "        print('---------------------------------------------------')\n",
    "        print('Total Inference Time in ms: ', total_infer_time)\n",
    "        print('Inference time for one image in ms: ', infer_time)\n",
    "        print('---------------------------------------------------')\n",
    "\n",
    "        record = {'model':[MODEL_NAME], \n",
    "                  'accuracy':[accuracy], \n",
    "                  'f1_score_global':[f1_global], \n",
    "                  'f1_score_individual':[f1_individual],\n",
    "                  'precision_global':[precision_global], \n",
    "                  'precision_individual':[precision_individual], \n",
    "                  'recall_global':[recall_global],\n",
    "                  'recall_individual':[recall_individual], \n",
    "                  'total_pred_time':[total_infer_time], \n",
    "                  'pred_time':[infer_time]}\n",
    "        \n",
    "        return record\n",
    "    else:\n",
    "        raise ValueError(f\"No model named {MODEL_NAME} found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_result(result):\n",
    "    csv_path = 'image_classification/results/multiclass_classification_results.csv'\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df_new = pd.DataFrame(result)\n",
    "        df = pd.concat([df, df_new], axis=0)\n",
    "        df.to_csv(csv_path)\n",
    "    else:\n",
    "        df_new = pd.DataFrame(result)\n",
    "        df.to_csv(csv_path)\n",
    "    \n",
    "    return \"Results logged successfully!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and CALLBACKS\n",
    "# Model 1\n",
    "MODEL_NAME = \"\"\n",
    "steps_per_epoch = len(train_data)//BATCH_SIZE\n",
    "checkpoint_path = f\"image_classification/ckpt/multiclass_classification/{MODEL_NAME}/best_model\"\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='image_classification/logs/multiclass_classification/{MODEL_NAME}')\n",
    "loss = BinaryCrossentropy()\n",
    "optim = Adam(learning_rate=10e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.1,\n",
    "                              patience=5, \n",
    "                              min_lr=10e-12, \n",
    "                              verbose=1)\n",
    "callback_collection = [checkpoint, tensorboard, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b510589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model and Train\n",
    "model_1 = model_generator(MODEL_NAME, CLASSES)\n",
    "model_1.compile(optimizer=optim, loss=loss, metrics='accuracy')\n",
    "history = model_1.fit(\n",
    "            train_data,\n",
    "            validation_data = valid_data,\n",
    "            epochs = EPOCHS,\n",
    "            callbacks=callback_collection\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_1.save(f'image_classification/Models/multiclass_classification/{MODEL_NAME}_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b484ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "result_1 = testing(TEST_IMG_DIR, MODEL_NAME)\n",
    "print(log_result(result_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-mac] *",
   "language": "python",
   "name": "conda-env-tf-mac-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
