{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiaQY50SBkqQ"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIloauIhIAYm",
        "outputId": "046614ee-fcee-43b8-c7f2-b11fc34fdf3e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/new_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vowQg0muEMti",
        "outputId": "e9637452-1a7a-4441-e343-0fef2b035d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/new_data.zip\n",
            "   creating: new_data/\n",
            "   creating: new_data/test/\n",
            "   creating: new_data/train/\n",
            "   creating: new_data/test/image/\n",
            "   creating: new_data/test/mask/\n",
            "   creating: new_data/train/image/\n",
            "   creating: new_data/train/mask/\n",
            "  inflating: new_data/test/image/01_test_0.png  \n",
            "  inflating: new_data/test/image/10_test_0.png  \n",
            "  inflating: new_data/test/image/15_test_0.png  \n",
            "  inflating: new_data/test/image/09_test_0.png  \n",
            "  inflating: new_data/test/image/18_test_0.png  \n",
            "  inflating: new_data/test/image/04_test_0.png  \n",
            "  inflating: new_data/test/image/03_test_0.png  \n",
            "  inflating: new_data/test/image/12_test_0.png  \n",
            "  inflating: new_data/test/image/20_test_0.png  \n",
            "  inflating: new_data/test/image/17_test_0.png  \n",
            "  inflating: new_data/test/image/06_test_0.png  \n",
            "  inflating: new_data/test/image/14_test_0.png  \n",
            "  inflating: new_data/test/image/08_test_0.png  \n",
            "  inflating: new_data/test/image/19_test_0.png  \n",
            "  inflating: new_data/test/image/05_test_0.png  \n",
            "  inflating: new_data/test/image/11_test_0.png  \n",
            "  inflating: new_data/test/image/16_test_0.png  \n",
            "  inflating: new_data/test/image/07_test_0.png  \n",
            "  inflating: new_data/test/image/02_test_0.png  \n",
            "  inflating: new_data/test/image/13_test_0.png  \n",
            "  inflating: new_data/test/mask/01_test_0.png  \n",
            "  inflating: new_data/test/mask/10_test_0.png  \n",
            "  inflating: new_data/test/mask/15_test_0.png  \n",
            "  inflating: new_data/test/mask/09_test_0.png  \n",
            "  inflating: new_data/test/mask/18_test_0.png  \n",
            "  inflating: new_data/test/mask/04_test_0.png  \n",
            "  inflating: new_data/test/mask/03_test_0.png  \n",
            "  inflating: new_data/test/mask/12_test_0.png  \n",
            "  inflating: new_data/test/mask/20_test_0.png  \n",
            "  inflating: new_data/test/mask/17_test_0.png  \n",
            "  inflating: new_data/test/mask/06_test_0.png  \n",
            "  inflating: new_data/test/mask/14_test_0.png  \n",
            "  inflating: new_data/test/mask/08_test_0.png  \n",
            "  inflating: new_data/test/mask/19_test_0.png  \n",
            "  inflating: new_data/test/mask/05_test_0.png  \n",
            "  inflating: new_data/test/mask/11_test_0.png  \n",
            "  inflating: new_data/test/mask/16_test_0.png  \n",
            "  inflating: new_data/test/mask/07_test_0.png  \n",
            "  inflating: new_data/test/mask/02_test_0.png  \n",
            "  inflating: new_data/test/mask/13_test_0.png  \n",
            "  inflating: new_data/train/image/38_training_3.png  \n",
            "  inflating: new_data/train/image/30_training_2.png  \n",
            "  inflating: new_data/train/image/25_training_2.png  \n",
            "  inflating: new_data/train/image/22_training_1.png  \n",
            "  inflating: new_data/train/image/37_training_1.png  \n",
            "  inflating: new_data/train/image/37_training_0.png  \n",
            "  inflating: new_data/train/image/22_training_0.png  \n",
            "  inflating: new_data/train/image/25_training_3.png  \n",
            "  inflating: new_data/train/image/30_training_3.png  \n",
            "  inflating: new_data/train/image/38_training_2.png  \n",
            "  inflating: new_data/train/image/30_training_1.png  \n",
            "  inflating: new_data/train/image/25_training_1.png  \n",
            "  inflating: new_data/train/image/38_training_0.png  \n",
            "  inflating: new_data/train/image/22_training_2.png  \n",
            "  inflating: new_data/train/image/37_training_2.png  \n",
            "  inflating: new_data/train/image/37_training_3.png  \n",
            "  inflating: new_data/train/image/22_training_3.png  \n",
            "  inflating: new_data/train/image/38_training_1.png  \n",
            "  inflating: new_data/train/image/25_training_0.png  \n",
            "  inflating: new_data/train/image/30_training_0.png  \n",
            "  inflating: new_data/train/image/39_training_1.png  \n",
            "  inflating: new_data/train/image/31_training_0.png  \n",
            "  inflating: new_data/train/image/24_training_0.png  \n",
            "  inflating: new_data/train/image/23_training_3.png  \n",
            "  inflating: new_data/train/image/36_training_3.png  \n",
            "  inflating: new_data/train/image/40_training_0.png  \n",
            "  inflating: new_data/train/image/40_training_1.png  \n",
            "  inflating: new_data/train/image/36_training_2.png  \n",
            "  inflating: new_data/train/image/23_training_2.png  \n",
            "  inflating: new_data/train/image/24_training_1.png  \n",
            "  inflating: new_data/train/image/31_training_1.png  \n",
            "  inflating: new_data/train/image/39_training_0.png  \n",
            "  inflating: new_data/train/image/31_training_3.png  \n",
            "  inflating: new_data/train/image/24_training_3.png  \n",
            "  inflating: new_data/train/image/39_training_2.png  \n",
            "  inflating: new_data/train/image/23_training_0.png  \n",
            "  inflating: new_data/train/image/36_training_0.png  \n",
            "  inflating: new_data/train/image/40_training_3.png  \n",
            "  inflating: new_data/train/image/40_training_2.png  \n",
            "  inflating: new_data/train/image/36_training_1.png  \n",
            "  inflating: new_data/train/image/23_training_1.png  \n",
            "  inflating: new_data/train/image/39_training_3.png  \n",
            "  inflating: new_data/train/image/24_training_2.png  \n",
            "  inflating: new_data/train/image/31_training_2.png  \n",
            "  inflating: new_data/train/image/29_training_1.png  \n",
            "  inflating: new_data/train/image/21_training_0.png  \n",
            "  inflating: new_data/train/image/34_training_0.png  \n",
            "  inflating: new_data/train/image/33_training_3.png  \n",
            "  inflating: new_data/train/image/26_training_3.png  \n",
            "  inflating: new_data/train/image/26_training_2.png  \n",
            "  inflating: new_data/train/image/33_training_2.png  \n",
            "  inflating: new_data/train/image/34_training_1.png  \n",
            "  inflating: new_data/train/image/21_training_1.png  \n",
            "  inflating: new_data/train/image/29_training_0.png  \n",
            "  inflating: new_data/train/image/21_training_3.png  \n",
            "  inflating: new_data/train/image/34_training_3.png  \n",
            "  inflating: new_data/train/image/29_training_2.png  \n",
            "  inflating: new_data/train/image/33_training_0.png  \n",
            "  inflating: new_data/train/image/26_training_0.png  \n",
            "  inflating: new_data/train/image/26_training_1.png  \n",
            "  inflating: new_data/train/image/33_training_1.png  \n",
            "  inflating: new_data/train/image/29_training_3.png  \n",
            "  inflating: new_data/train/image/34_training_2.png  \n",
            "  inflating: new_data/train/image/21_training_2.png  \n",
            "  inflating: new_data/train/image/28_training_3.png  \n",
            "  inflating: new_data/train/image/35_training_2.png  \n",
            "  inflating: new_data/train/image/32_training_1.png  \n",
            "  inflating: new_data/train/image/27_training_1.png  \n",
            "  inflating: new_data/train/image/27_training_0.png  \n",
            "  inflating: new_data/train/image/32_training_0.png  \n",
            "  inflating: new_data/train/image/35_training_3.png  \n",
            "  inflating: new_data/train/image/28_training_2.png  \n",
            "  inflating: new_data/train/image/35_training_1.png  \n",
            "  inflating: new_data/train/image/28_training_0.png  \n",
            "  inflating: new_data/train/image/32_training_2.png  \n",
            "  inflating: new_data/train/image/27_training_2.png  \n",
            "  inflating: new_data/train/image/27_training_3.png  \n",
            "  inflating: new_data/train/image/32_training_3.png  \n",
            "  inflating: new_data/train/image/28_training_1.png  \n",
            "  inflating: new_data/train/image/35_training_0.png  \n",
            "  inflating: new_data/train/mask/38_training_3.png  \n",
            "  inflating: new_data/train/mask/30_training_2.png  \n",
            "  inflating: new_data/train/mask/25_training_2.png  \n",
            "  inflating: new_data/train/mask/22_training_1.png  \n",
            "  inflating: new_data/train/mask/37_training_1.png  \n",
            "  inflating: new_data/train/mask/37_training_0.png  \n",
            "  inflating: new_data/train/mask/22_training_0.png  \n",
            "  inflating: new_data/train/mask/25_training_3.png  \n",
            "  inflating: new_data/train/mask/30_training_3.png  \n",
            "  inflating: new_data/train/mask/38_training_2.png  \n",
            "  inflating: new_data/train/mask/30_training_1.png  \n",
            "  inflating: new_data/train/mask/25_training_1.png  \n",
            "  inflating: new_data/train/mask/38_training_0.png  \n",
            "  inflating: new_data/train/mask/22_training_2.png  \n",
            "  inflating: new_data/train/mask/37_training_2.png  \n",
            "  inflating: new_data/train/mask/37_training_3.png  \n",
            "  inflating: new_data/train/mask/22_training_3.png  \n",
            "  inflating: new_data/train/mask/38_training_1.png  \n",
            "  inflating: new_data/train/mask/25_training_0.png  \n",
            "  inflating: new_data/train/mask/30_training_0.png  \n",
            "  inflating: new_data/train/mask/39_training_1.png  \n",
            "  inflating: new_data/train/mask/31_training_0.png  \n",
            "  inflating: new_data/train/mask/24_training_0.png  \n",
            "  inflating: new_data/train/mask/23_training_3.png  \n",
            "  inflating: new_data/train/mask/36_training_3.png  \n",
            "  inflating: new_data/train/mask/40_training_0.png  \n",
            "  inflating: new_data/train/mask/40_training_1.png  \n",
            "  inflating: new_data/train/mask/36_training_2.png  \n",
            "  inflating: new_data/train/mask/23_training_2.png  \n",
            "  inflating: new_data/train/mask/24_training_1.png  \n",
            "  inflating: new_data/train/mask/31_training_1.png  \n",
            "  inflating: new_data/train/mask/39_training_0.png  \n",
            "  inflating: new_data/train/mask/31_training_3.png  \n",
            "  inflating: new_data/train/mask/24_training_3.png  \n",
            "  inflating: new_data/train/mask/39_training_2.png  \n",
            "  inflating: new_data/train/mask/23_training_0.png  \n",
            "  inflating: new_data/train/mask/36_training_0.png  \n",
            "  inflating: new_data/train/mask/40_training_3.png  \n",
            "  inflating: new_data/train/mask/40_training_2.png  \n",
            "  inflating: new_data/train/mask/36_training_1.png  \n",
            "  inflating: new_data/train/mask/23_training_1.png  \n",
            "  inflating: new_data/train/mask/39_training_3.png  \n",
            "  inflating: new_data/train/mask/24_training_2.png  \n",
            "  inflating: new_data/train/mask/31_training_2.png  \n",
            "  inflating: new_data/train/mask/29_training_1.png  \n",
            "  inflating: new_data/train/mask/21_training_0.png  \n",
            "  inflating: new_data/train/mask/34_training_0.png  \n",
            "  inflating: new_data/train/mask/33_training_3.png  \n",
            "  inflating: new_data/train/mask/26_training_3.png  \n",
            "  inflating: new_data/train/mask/26_training_2.png  \n",
            "  inflating: new_data/train/mask/33_training_2.png  \n",
            "  inflating: new_data/train/mask/34_training_1.png  \n",
            "  inflating: new_data/train/mask/21_training_1.png  \n",
            "  inflating: new_data/train/mask/29_training_0.png  \n",
            "  inflating: new_data/train/mask/21_training_3.png  \n",
            "  inflating: new_data/train/mask/34_training_3.png  \n",
            "  inflating: new_data/train/mask/29_training_2.png  \n",
            "  inflating: new_data/train/mask/33_training_0.png  \n",
            "  inflating: new_data/train/mask/26_training_0.png  \n",
            "  inflating: new_data/train/mask/26_training_1.png  \n",
            "  inflating: new_data/train/mask/33_training_1.png  \n",
            "  inflating: new_data/train/mask/29_training_3.png  \n",
            "  inflating: new_data/train/mask/34_training_2.png  \n",
            "  inflating: new_data/train/mask/21_training_2.png  \n",
            "  inflating: new_data/train/mask/28_training_3.png  \n",
            "  inflating: new_data/train/mask/35_training_2.png  \n",
            "  inflating: new_data/train/mask/32_training_1.png  \n",
            "  inflating: new_data/train/mask/27_training_1.png  \n",
            "  inflating: new_data/train/mask/27_training_0.png  \n",
            "  inflating: new_data/train/mask/32_training_0.png  \n",
            "  inflating: new_data/train/mask/35_training_3.png  \n",
            "  inflating: new_data/train/mask/28_training_2.png  \n",
            "  inflating: new_data/train/mask/35_training_1.png  \n",
            "  inflating: new_data/train/mask/28_training_0.png  \n",
            "  inflating: new_data/train/mask/32_training_2.png  \n",
            "  inflating: new_data/train/mask/27_training_2.png  \n",
            "  inflating: new_data/train/mask/27_training_3.png  \n",
            "  inflating: new_data/train/mask/32_training_3.png  \n",
            "  inflating: new_data/train/mask/28_training_1.png  \n",
            "  inflating: new_data/train/mask/35_training_0.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPuRKEfBoet"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH1r-AuFIFyw"
      },
      "source": [
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "from __future__ import print_function\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from tensorflow.keras.models import load_model as load_initial_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_HCART1BqqU"
      },
      "source": [
        "# Handcrafted Metrics For Additional Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcCvZQS9rY5V"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "  smooth = 0.0\n",
        "  y_true_f = keras.flatten(y_true)\n",
        "  y_pred_f = keras.flatten(y_pred)\n",
        "  intersection = keras.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + smooth) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "  y_true_f = keras.flatten(y_true)\n",
        "  y_pred_f = keras.flatten(y_pred)\n",
        "  intersection = keras.sum ( y_true_f * y_pred_f)\n",
        "  union = keras.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "  return intersection/union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVt1cPWwByok"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnPgkAyMIGqB"
      },
      "source": [
        "def unet(pretrained_weights = None,input_size = (608,576,1)):\n",
        "  inputs = Input(input_size)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "  drop4 = Dropout(0.5)(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "  drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "  merge9 = concatenate([conv1,up9], axis = 3)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "  model = Model(inputs,conv10)\n",
        "\n",
        "  model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy',dice_coef,jacard, tf.keras.metrics.AUC(), tf.keras.metrics.MeanIoU(num_classes=2),\n",
        "                                                                                      tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "    \n",
        "  #model.summary()\n",
        "\n",
        "  if(pretrained_weights):\n",
        "    model.load_weights(pretrained_weights)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNGQrmFeB0MJ"
      },
      "source": [
        "# Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuZjmPUBIQsX"
      },
      "source": [
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "  if(flag_multi_class):\n",
        "    img = img / 255\n",
        "    mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "    new_mask = np.zeros(mask.shape + (num_class,))\n",
        "    for i in range(num_class):\n",
        "        #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "        #index = np.where(mask == i)\n",
        "        #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "        #new_mask[index_mask] = 1\n",
        "        new_mask[mask == i,i] = 1\n",
        "    new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "    mask = new_mask\n",
        "  elif (np.max(img) > 1):\n",
        "    img = img / 255\n",
        "    mask = mask /255\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "  return (img,mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX__zdI9BXI8"
      },
      "source": [
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (608,576),seed = 1):\n",
        "  image_datagen = ImageDataGenerator(**aug_dict)\n",
        "  mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "  image_generator = image_datagen.flow_from_directory(\n",
        "      train_path,\n",
        "      classes = [image_folder],\n",
        "      class_mode = None,\n",
        "      color_mode = image_color_mode,\n",
        "      target_size = target_size,\n",
        "      batch_size = batch_size,\n",
        "      save_to_dir = save_to_dir,\n",
        "      save_prefix  = image_save_prefix,\n",
        "      seed = seed)\n",
        "  mask_generator = mask_datagen.flow_from_directory(\n",
        "      train_path,\n",
        "      classes = [mask_folder],\n",
        "      class_mode = None,\n",
        "      color_mode = mask_color_mode,\n",
        "      target_size = target_size,\n",
        "      batch_size = batch_size,\n",
        "      save_to_dir = save_to_dir,\n",
        "      save_prefix  = mask_save_prefix,\n",
        "      seed = seed)\n",
        "  train_generator = zip(image_generator, mask_generator)\n",
        "  for (img,mask) in train_generator:\n",
        "    img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "    yield (img,mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns8cuqZDBVCM"
      },
      "source": [
        "def testGenerator(test_path, target_size = (608,576),flag_multi_class = False,as_gray = True):\n",
        "  image_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  mask_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  for img_name in sorted(os.listdir(test_path + \"/images\")):\n",
        "      img = io.imread(os.path.join(test_path + \"/images\",img_name),as_gray = as_gray)\n",
        "      img = img / 255\n",
        "      img = trans.resize(img,target_size)\n",
        "      img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "      img = np.reshape(img,(1,)+img.shape)\n",
        "      yield img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ujxwRxBS3Z"
      },
      "source": [
        "def testGenerator2(batch_size,test_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (608,576),seed = 1):\n",
        "  image_datagen = ImageDataGenerator(**aug_dict)\n",
        "  mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "  image_generator = image_datagen.flow_from_directory(\n",
        "      test_path,\n",
        "      classes = [image_folder],\n",
        "      class_mode = None,\n",
        "      color_mode = image_color_mode,\n",
        "      target_size = target_size,\n",
        "      batch_size = batch_size,\n",
        "      save_to_dir = save_to_dir,\n",
        "      save_prefix  = image_save_prefix,\n",
        "      seed = seed)\n",
        "  mask_generator = mask_datagen.flow_from_directory(\n",
        "      test_path,\n",
        "      classes = [mask_folder],\n",
        "      class_mode = None,\n",
        "      color_mode = mask_color_mode,\n",
        "      target_size = target_size,\n",
        "      batch_size = batch_size,\n",
        "      save_to_dir = save_to_dir,\n",
        "      save_prefix  = mask_save_prefix,\n",
        "      seed = seed)\n",
        "  test_generator = zip(image_generator, mask_generator)\n",
        "  for (img,mask) in test_generator:\n",
        "    img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "    yield (img,mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNv00UXuBJCI"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWdo9rMNC8UH"
      },
      "source": [
        "def pad(input_folder, output_folder):\n",
        "  for file in sorted(os.listdir(input_folder)):\n",
        "    if '.png' in file:\n",
        "      tmp = cv2.imread(input_folder + '/' + file, 0)\n",
        "      tmp = cv2.copyMakeBorder(tmp.copy(),12,12,5,6,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
        "      io.imsave(output_folder + '/' + file, tmp)\n",
        "  print('Padding is done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_fxvrB2A5bL"
      },
      "source": [
        "def crop(input_folder, output_folder):\n",
        "  for file in sorted(os.listdir(input_folder)):\n",
        "    if '.png' in file:\n",
        "      tmp = cv2.imread(input_folder + '/' + file, 0)\n",
        "      tmp = tmp[12:-12, 5:-6]\n",
        "      io.imsave(output_folder + '/' + file, tmp)\n",
        "  print('Cropping is done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "    img_out = np.zeros(img.shape + (3,))\n",
        "    for i in range(num_class):\n",
        "        img_out[img == i,:] = color_dict[i]\n",
        "    return img_out "
      ],
      "metadata": {
        "id": "B9wOk9NERpbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syDqXJGVLW9U"
      },
      "source": [
        "def saveResult_drive(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "  for i,item in enumerate(npyfile):\n",
        "      img = item[:,:,0]\n",
        "      img[img >= 0.5] = 255\n",
        "      img[img < 0.5] = 0\n",
        "      io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3DKunl8dVFU"
      },
      "source": [
        "def threshold(folder):\n",
        "  for img in sorted(os.listdir(folder)):\n",
        "    tmp = cv2.imread(folder + '/' + img, 0)\n",
        "    _, tmp = cv2.threshold(tmp,115,255,cv2.THRESH_BINARY)\n",
        "    io.imsave(folder + '/' + img, tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZdSCsX8eQG7"
      },
      "source": [
        "def set_order(input_folder, output_folder):\n",
        "\n",
        "  for img in sorted(os.listdir(input_folder)):\n",
        "\n",
        "    if int(img.split('.')[0]) == 0:\n",
        "      tmp = cv2.imread(input_folder  + '/' + img, 0)\n",
        "      io.imsave(output_folder + '/' + str(int(img.split('.')[0])+1) + '.png', tmp)\n",
        "    elif int(img.split('.')[0]) >= 1 and int(img.split('.')[0]) <= 10:\n",
        "      tmp = cv2.imread(input_folder  + '/' + img, 0)\n",
        "      io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
        "    elif int(img.split('.')[0]) >= 13 and int(img.split('.')[0]) <= 19:\n",
        "      tmp = cv2.imread(input_folder  + '/' + img, 0)\n",
        "      io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
        "    elif int(img.split('.')[0]) == 11:\n",
        "      tmp = cv2.imread(input_folder  + '/' + img, 0)\n",
        "      io.imsave(output_folder + '/' + str(int(img.split('.')[0])-9) + '.png', tmp)\n",
        "    elif int(img.split('.')[0]) == 12:\n",
        "      tmp = cv2.imread(input_folder  + '/' + img, 0)\n",
        "      io.imsave(output_folder + '/' + str(int(img.split('.')[0])+8) + '.png', tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBpbFMqXLIuk"
      },
      "source": [
        "def dice(true_mask, pred_mask, non_seg_score=1.0):\n",
        "    \"\"\"\n",
        "        Computes the Dice coefficient.\n",
        "        Args:\n",
        "            true_mask : Array of arbitrary shape.\n",
        "            pred_mask : Array with the same shape than true_mask.  \n",
        "        \n",
        "        Returns:\n",
        "            A scalar representing the Dice coefficient between the two segmentations. \n",
        "        \n",
        "    \"\"\"\n",
        "    assert true_mask.shape == pred_mask.shape\n",
        "\n",
        "    true_mask = np.asarray(true_mask).astype(np.bool)\n",
        "    pred_mask = np.asarray(pred_mask).astype(np.bool)\n",
        "\n",
        "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
        "    im_sum = true_mask.sum() + pred_mask.sum()\n",
        "    if im_sum == 0:\n",
        "        return non_seg_score\n",
        "\n",
        "    # Compute Dice coefficient\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    return 2. * intersection.sum() / im_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qkknx_VeZoJ"
      },
      "source": [
        "def mean_dice(true_path, pred_path):\n",
        "  \n",
        "  sum = 0\n",
        "  \n",
        "  for img in sorted(os.listdir(pred_path)):\n",
        "    \n",
        "    true_tmp = cv2.imread(true_path + '/' + img, 0)\n",
        "    pred_tmp = cv2.imread(pred_path + '/' + img, 0)\n",
        "    \n",
        "    a = dice(true_tmp, pred_tmp)\n",
        "    print(a)\n",
        "    sum += a\n",
        "  \n",
        "  return sum/len(os.listdir(true_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiIBbH4DKkUD"
      },
      "source": [
        "# DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY48ylfTKmKw"
      },
      "source": [
        "LOG_PATH      = '/content/drive/MyDrive/nerve_segmentation/U-Net/logs'\n",
        "RESULT_PATH   = '/content/drive/MyDrive/nerve_segmentation/U-Net/test_results'\n",
        "MODEL_PATH    = '/content/drive/MyDrive/nerve_segmentation/U-Net/models'\n",
        "\n",
        "TRAIN_PATH    = '/content/new_data/train'\n",
        "VAL_PATH      = '/content/new_data/test'\n",
        "TEST_PATH     = '/content/new_data/test'\n",
        "\n",
        "TMP_TRAIN     = '/content/nerve_segmentation/tmp_train'\n",
        "TMP_TEST      = '/content/nerve_segmentation/tmp_test'\n",
        "TMP_VAL       = '/content/nerve_segmentation/tmp_val'\n",
        "TMP_RESULT    = '/content/nerve_segmentation/tmp_result'\n",
        "\n",
        "if (os.path.isdir(LOG_PATH) and os.path.isdir(RESULT_PATH) and \\\n",
        "    os.path.isdir(MODEL_PATH) and os.path.isdir(TRAIN_PATH)) and \\\n",
        "    os.path.isdir(TEST_PATH) and os.path.isdir(VAL_PATH) and \\\n",
        "    os.path.isdir(TMP_TRAIN) and os.path.isdir(TMP_TEST) and \\\n",
        "    os.path.isdir(TMP_VAL) and os.path.isdir(TMP_RESULT) == 0:\n",
        "    raise OSError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFj8N0Dbhitj"
      },
      "source": [
        "## Train Many Epochs at Once "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daLKmP7nLW9V"
      },
      "source": [
        "def train_eval_drive(save_name, num_train, num_test, initial_model_path, train_batch = 3, test_batch = 3, epoch = 5):\n",
        "  \n",
        "  shutil.rmtree(TMP_TRAIN, ignore_errors=False, onerror=None)\n",
        "  os.mkdir(TMP_TRAIN)\n",
        "  os.mkdir(TMP_TRAIN + \"/images\")\n",
        "  os.mkdir(TMP_TRAIN + \"/labels\")\n",
        "\n",
        "  shutil.rmtree(TMP_TEST, ignore_errors=False, onerror=None)\n",
        "  os.mkdir(TMP_TEST)\n",
        "  os.mkdir(TMP_TEST + \"/images\")\n",
        "  os.mkdir(TMP_TEST + \"/labels\")\n",
        "  \n",
        "  \n",
        "  shutil.rmtree(TMP_VAL, ignore_errors=False, onerror=None)\n",
        "  os.mkdir(TMP_VAL)\n",
        "  os.mkdir(TMP_VAL + \"/images\")\n",
        "  os.mkdir(TMP_VAL + \"/labels\")\n",
        "  \n",
        "\n",
        "  pad(TRAIN_PATH + '/images', TMP_TRAIN + '/images')\n",
        "  pad(TRAIN_PATH + '/labels', TMP_TRAIN + '/labels')\n",
        "\n",
        "  pad(TEST_PATH + '/images', TMP_TEST + '/images')\n",
        "  pad(TEST_PATH + '/labels', TMP_TEST + '/labels')\n",
        "  \n",
        "  pad(VAL_PATH + '/images', TMP_VAL + '/images')\n",
        "  pad(VAL_PATH + '/labels', TMP_VAL + '/labels')\n",
        "  \n",
        "  data_gen_args = dict()\n",
        "  train_generator = trainGenerator(train_batch, TMP_TRAIN, 'images', 'labels', data_gen_args, save_to_dir = None, target_size=(608,576))\n",
        "  test_generator = testGenerator2(test_batch, TMP_TEST, 'images', 'labels', data_gen_args, save_to_dir = None, target_size=(608,576))\n",
        "\n",
        "  model = unet(input_size=(608,576,1))\n",
        "  if initial_model_path != None:\n",
        "    model.load_weights(initial_model_path)\n",
        "\n",
        "  model_checkpoint = ModelCheckpoint(MODEL_PATH + \"/\" + save_name +\".hdf5\", monitor='loss',verbose=1, save_best_only=True)\n",
        "\n",
        "  model_history = model.fit_generator(train_generator, steps_per_epoch=num_train//train_batch, epochs=epoch, callbacks=[model_checkpoint],\n",
        "                                      validation_data=test_generator, validation_steps=num_test//test_batch)\n",
        "  \n",
        "  log_file = open(LOG_PATH + \"/log_{}.pkl\".format(save_name), \"wb\")#history file\n",
        "  pickle.dump(model_history.history, log_file)\n",
        "  log_file.close()\n",
        "\n",
        "  test_generator_2 = testGenerator(TMP_TEST, target_size=(608,576))\n",
        "  results = model.predict_generator(test_generator_2,verbose=1)\n",
        "\n",
        "  shutil.rmtree(TMP_RESULT, ignore_errors=False, onerror=None)\n",
        "  os.mkdir(TMP_RESULT)\n",
        "  saveResult_drive(TMP_RESULT, results)\n",
        "  \n",
        "  os.mkdir(RESULT_PATH + '/' + save_name)\n",
        "  crop(TMP_RESULT, RESULT_PATH + '/' + save_name)\n",
        "\n",
        "  threshold(RESULT_PATH + '/' + save_name)\n",
        "\n",
        "  shutil.rmtree(RESULT_PATH + '/download', ignore_errors=False, onerror=None)\n",
        "  os.mkdir(RESULT_PATH + '/download')\n",
        "  set_order(RESULT_PATH + '/' + save_name, RESULT_PATH + '/download')\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_PwUgZKsA-g"
      },
      "source": [
        "train_sample_number = len(os.listdir(TRAIN_PATH + '/images'))\n",
        "test_sample_number  = len(os.listdir(TEST_PATH + '/images'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5gdl-KHIZUt",
        "outputId": "fe8d3025-8ace-4258-b16f-ed3ca809d436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j14e8MXUDaOd"
      },
      "source": [
        "SAVE_NAME = 'my_model2'\n",
        "INITIAL_MODEL_PATH = None\n",
        "EPOCH = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7V2TCeCLf0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5221678f-1457-407c-b3c7-8172236b5f89"
      },
      "source": [
        "res = train_eval_drive(SAVE_NAME, initial_model_path= INITIAL_MODEL_PATH, epoch= EPOCH, train_batch = 3, test_batch = 3, num_train = train_sample_number, num_test= test_sample_number)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padding is done.\n",
            "Padding is done.\n",
            "Padding is done.\n",
            "Padding is done.\n",
            "Padding is done.\n",
            "Padding is done.\n",
            "Found 80 images belonging to 1 classes.\n",
            "Found 80 images belonging to 1 classes.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "<ipython-input-70-e5e6484cf365>:39: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model_history = model.fit_generator(train_generator, steps_per_epoch=num_train//train_batch, epochs=epoch, callbacks=[model_checkpoint],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.8866 - dice_coef: 0.1401 - jacard: 0.0754 - auc_7: 0.5004 - mean_io_u_7: 0.4592 - precision_7: 0.0765 - recall_7: 0.0353Found 20 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n",
            "\n",
            "Epoch 1: loss improved from inf to 0.69422, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 45s 2s/step - loss: 0.6942 - accuracy: 0.8866 - dice_coef: 0.1401 - jacard: 0.0754 - auc_7: 0.5004 - mean_io_u_7: 0.4592 - precision_7: 0.0765 - recall_7: 0.0353 - val_loss: 0.6921 - val_accuracy: 0.9188 - val_dice_coef: 0.1397 - val_jacard: 0.0751 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4594 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 2/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.9177 - dice_coef: 0.1413 - jacard: 0.0761 - auc_7: 0.5000 - mean_io_u_7: 0.4588 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 2: loss improved from 0.69422 to 0.69154, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6915 - accuracy: 0.9177 - dice_coef: 0.1413 - jacard: 0.0761 - auc_7: 0.5000 - mean_io_u_7: 0.4588 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6910 - val_accuracy: 0.9181 - val_dice_coef: 0.1406 - val_jacard: 0.0756 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4591 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 3/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.9188 - dice_coef: 0.1395 - jacard: 0.0750 - auc_7: 0.5000 - mean_io_u_7: 0.4594 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 3: loss improved from 0.69154 to 0.69045, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6905 - accuracy: 0.9188 - dice_coef: 0.1395 - jacard: 0.0750 - auc_7: 0.5000 - mean_io_u_7: 0.4594 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6899 - val_accuracy: 0.9186 - val_dice_coef: 0.1400 - val_jacard: 0.0753 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4593 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 4/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.9179 - dice_coef: 0.1407 - jacard: 0.0757 - auc_7: 0.5022 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 4: loss improved from 0.69045 to 0.68938, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6894 - accuracy: 0.9179 - dice_coef: 0.1407 - jacard: 0.0757 - auc_7: 0.5022 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6888 - val_accuracy: 0.9192 - val_dice_coef: 0.1390 - val_jacard: 0.0747 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4596 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 5/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.9194 - dice_coef: 0.1385 - jacard: 0.0744 - auc_7: 0.5000 - mean_io_u_7: 0.4597 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 5: loss improved from 0.68938 to 0.68828, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6883 - accuracy: 0.9194 - dice_coef: 0.1385 - jacard: 0.0744 - auc_7: 0.5000 - mean_io_u_7: 0.4597 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6877 - val_accuracy: 0.9182 - val_dice_coef: 0.1405 - val_jacard: 0.0755 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4591 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 6/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.9177 - dice_coef: 0.1413 - jacard: 0.0760 - auc_7: 0.5000 - mean_io_u_7: 0.4589 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 6: loss improved from 0.68828 to 0.68723, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6872 - accuracy: 0.9177 - dice_coef: 0.1413 - jacard: 0.0760 - auc_7: 0.5000 - mean_io_u_7: 0.4589 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6867 - val_accuracy: 0.9195 - val_dice_coef: 0.1385 - val_jacard: 0.0744 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4597 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 7/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.9179 - dice_coef: 0.1408 - jacard: 0.0758 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 7: loss improved from 0.68723 to 0.68616, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6862 - accuracy: 0.9179 - dice_coef: 0.1408 - jacard: 0.0758 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6856 - val_accuracy: 0.9187 - val_dice_coef: 0.1396 - val_jacard: 0.0750 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4594 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 8/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6851 - accuracy: 0.9179 - dice_coef: 0.1408 - jacard: 0.0758 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 8: loss improved from 0.68616 to 0.68509, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6851 - accuracy: 0.9179 - dice_coef: 0.1408 - jacard: 0.0758 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6845 - val_accuracy: 0.9183 - val_dice_coef: 0.1402 - val_jacard: 0.0754 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4591 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 9/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.9185 - dice_coef: 0.1400 - jacard: 0.0753 - auc_7: 0.5000 - mean_io_u_7: 0.4592 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 9: loss improved from 0.68509 to 0.68401, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6840 - accuracy: 0.9185 - dice_coef: 0.1400 - jacard: 0.0753 - auc_7: 0.5000 - mean_io_u_7: 0.4592 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6834 - val_accuracy: 0.9190 - val_dice_coef: 0.1391 - val_jacard: 0.0748 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4595 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 10/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.9174 - dice_coef: 0.1416 - jacard: 0.0762 - auc_7: 0.5000 - mean_io_u_7: 0.4587 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 10: loss improved from 0.68401 to 0.68297, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6830 - accuracy: 0.9174 - dice_coef: 0.1416 - jacard: 0.0762 - auc_7: 0.5000 - mean_io_u_7: 0.4587 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6824 - val_accuracy: 0.9189 - val_dice_coef: 0.1393 - val_jacard: 0.0749 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4595 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 11/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.9190 - dice_coef: 0.1388 - jacard: 0.0746 - auc_7: 0.5000 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 11: loss improved from 0.68297 to 0.68187, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6819 - accuracy: 0.9190 - dice_coef: 0.1388 - jacard: 0.0746 - auc_7: 0.5000 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6813 - val_accuracy: 0.9180 - val_dice_coef: 0.1406 - val_jacard: 0.0756 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4590 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 12/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.9191 - dice_coef: 0.1389 - jacard: 0.0746 - auc_7: 0.5034 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 12: loss improved from 0.68187 to 0.68080, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6808 - accuracy: 0.9191 - dice_coef: 0.1389 - jacard: 0.0746 - auc_7: 0.5034 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6803 - val_accuracy: 0.9185 - val_dice_coef: 0.1398 - val_jacard: 0.0752 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4593 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 13/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.9175 - dice_coef: 0.1412 - jacard: 0.0760 - auc_7: 0.5000 - mean_io_u_7: 0.4587 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 13: loss improved from 0.68080 to 0.67979, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6798 - accuracy: 0.9175 - dice_coef: 0.1412 - jacard: 0.0760 - auc_7: 0.5000 - mean_io_u_7: 0.4587 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6792 - val_accuracy: 0.9185 - val_dice_coef: 0.1398 - val_jacard: 0.0752 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4593 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 14/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6787 - accuracy: 0.9191 - dice_coef: 0.1388 - jacard: 0.0746 - auc_7: 0.5000 - mean_io_u_7: 0.4596 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 14: loss improved from 0.67979 to 0.67868, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6787 - accuracy: 0.9191 - dice_coef: 0.1388 - jacard: 0.0746 - auc_7: 0.5000 - mean_io_u_7: 0.4596 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6782 - val_accuracy: 0.9187 - val_dice_coef: 0.1396 - val_jacard: 0.0750 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4593 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 15/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.9166 - dice_coef: 0.1425 - jacard: 0.0768 - auc_7: 0.5000 - mean_io_u_7: 0.4583 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 15: loss improved from 0.67868 to 0.67772, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 42s 2s/step - loss: 0.6777 - accuracy: 0.9166 - dice_coef: 0.1425 - jacard: 0.0768 - auc_7: 0.5000 - mean_io_u_7: 0.4583 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6771 - val_accuracy: 0.9194 - val_dice_coef: 0.1384 - val_jacard: 0.0744 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4597 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 16/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.9180 - dice_coef: 0.1404 - jacard: 0.0756 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 16: loss improved from 0.67772 to 0.67663, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6766 - accuracy: 0.9180 - dice_coef: 0.1404 - jacard: 0.0756 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6761 - val_accuracy: 0.9174 - val_dice_coef: 0.1413 - val_jacard: 0.0760 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4587 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 17/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.9183 - dice_coef: 0.1402 - jacard: 0.0754 - auc_7: 0.5000 - mean_io_u_7: 0.4591 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 17: loss improved from 0.67663 to 0.67557, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6756 - accuracy: 0.9183 - dice_coef: 0.1402 - jacard: 0.0754 - auc_7: 0.5000 - mean_io_u_7: 0.4591 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6750 - val_accuracy: 0.9195 - val_dice_coef: 0.1382 - val_jacard: 0.0743 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4597 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 18/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6744 - accuracy: 0.9208 - dice_coef: 0.1363 - jacard: 0.0732 - auc_7: 0.5000 - mean_io_u_7: 0.4604 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 18: loss improved from 0.67557 to 0.67440, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6744 - accuracy: 0.9208 - dice_coef: 0.1363 - jacard: 0.0732 - auc_7: 0.5000 - mean_io_u_7: 0.4604 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6740 - val_accuracy: 0.9183 - val_dice_coef: 0.1398 - val_jacard: 0.0752 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4592 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 19/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.9169 - dice_coef: 0.1418 - jacard: 0.0763 - auc_7: 0.5000 - mean_io_u_7: 0.4584 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 19: loss improved from 0.67440 to 0.67354, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6735 - accuracy: 0.9169 - dice_coef: 0.1418 - jacard: 0.0763 - auc_7: 0.5000 - mean_io_u_7: 0.4584 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6729 - val_accuracy: 0.9187 - val_dice_coef: 0.1394 - val_jacard: 0.0749 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4593 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 20/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.9170 - dice_coef: 0.1419 - jacard: 0.0764 - auc_7: 0.4901 - mean_io_u_7: 0.4585 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 20: loss improved from 0.67354 to 0.67250, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6725 - accuracy: 0.9170 - dice_coef: 0.1419 - jacard: 0.0764 - auc_7: 0.4901 - mean_io_u_7: 0.4585 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6719 - val_accuracy: 0.9188 - val_dice_coef: 0.1391 - val_jacard: 0.0748 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4594 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 21/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.9204 - dice_coef: 0.1365 - jacard: 0.0733 - auc_7: 0.5000 - mean_io_u_7: 0.4602 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 21: loss improved from 0.67250 to 0.67128, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6713 - accuracy: 0.9204 - dice_coef: 0.1365 - jacard: 0.0733 - auc_7: 0.5000 - mean_io_u_7: 0.4602 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6709 - val_accuracy: 0.9179 - val_dice_coef: 0.1405 - val_jacard: 0.0756 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4589 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 22/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6705 - accuracy: 0.9165 - dice_coef: 0.1424 - jacard: 0.0767 - auc_7: 0.5000 - mean_io_u_7: 0.4582 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 22: loss improved from 0.67128 to 0.67046, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6705 - accuracy: 0.9165 - dice_coef: 0.1424 - jacard: 0.0767 - auc_7: 0.5000 - mean_io_u_7: 0.4582 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6699 - val_accuracy: 0.9168 - val_dice_coef: 0.1420 - val_jacard: 0.0765 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4584 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 23/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6693 - accuracy: 0.9184 - dice_coef: 0.1395 - jacard: 0.0750 - auc_7: 0.5000 - mean_io_u_7: 0.4592 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 23: loss improved from 0.67046 to 0.66932, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6693 - accuracy: 0.9184 - dice_coef: 0.1395 - jacard: 0.0750 - auc_7: 0.5000 - mean_io_u_7: 0.4592 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6687 - val_accuracy: 0.9189 - val_dice_coef: 0.1389 - val_jacard: 0.0746 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4595 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 24/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.9181 - dice_coef: 0.1398 - jacard: 0.0752 - auc_7: 0.5000 - mean_io_u_7: 0.4591 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 24: loss improved from 0.66932 to 0.66830, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6683 - accuracy: 0.9181 - dice_coef: 0.1398 - jacard: 0.0752 - auc_7: 0.5000 - mean_io_u_7: 0.4591 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6678 - val_accuracy: 0.9181 - val_dice_coef: 0.1401 - val_jacard: 0.0753 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4590 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 25/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.9189 - dice_coef: 0.1389 - jacard: 0.0747 - auc_7: 0.5000 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 25: loss improved from 0.66830 to 0.66722, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 40s 2s/step - loss: 0.6672 - accuracy: 0.9189 - dice_coef: 0.1389 - jacard: 0.0747 - auc_7: 0.5000 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6667 - val_accuracy: 0.9181 - val_dice_coef: 0.1400 - val_jacard: 0.0753 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4591 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 26/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.9180 - dice_coef: 0.1402 - jacard: 0.0754 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 26: loss improved from 0.66722 to 0.66625, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 43s 2s/step - loss: 0.6663 - accuracy: 0.9180 - dice_coef: 0.1402 - jacard: 0.0754 - auc_7: 0.5000 - mean_io_u_7: 0.4590 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6657 - val_accuracy: 0.9187 - val_dice_coef: 0.1391 - val_jacard: 0.0748 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4594 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 27/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.9185 - dice_coef: 0.1393 - jacard: 0.0749 - auc_7: 0.5000 - mean_io_u_7: 0.4593 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 27: loss improved from 0.66625 to 0.66519, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6652 - accuracy: 0.9185 - dice_coef: 0.1393 - jacard: 0.0749 - auc_7: 0.5000 - mean_io_u_7: 0.4593 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6646 - val_accuracy: 0.9197 - val_dice_coef: 0.1377 - val_jacard: 0.0740 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4598 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 28/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6641 - accuracy: 0.9187 - dice_coef: 0.1390 - jacard: 0.0747 - auc_7: 0.5080 - mean_io_u_7: 0.4594 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 28: loss improved from 0.66519 to 0.66415, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6641 - accuracy: 0.9187 - dice_coef: 0.1390 - jacard: 0.0747 - auc_7: 0.5080 - mean_io_u_7: 0.4594 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6637 - val_accuracy: 0.9180 - val_dice_coef: 0.1401 - val_jacard: 0.0753 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4590 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 29/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6632 - accuracy: 0.9177 - dice_coef: 0.1408 - jacard: 0.0758 - auc_7: 0.5000 - mean_io_u_7: 0.4588 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 29: loss improved from 0.66415 to 0.66320, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6632 - accuracy: 0.9177 - dice_coef: 0.1408 - jacard: 0.0758 - auc_7: 0.5000 - mean_io_u_7: 0.4588 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6626 - val_accuracy: 0.9182 - val_dice_coef: 0.1397 - val_jacard: 0.0751 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4591 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
            "Epoch 30/30\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.9190 - dice_coef: 0.1386 - jacard: 0.0745 - auc_7: 0.5000 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
            "Epoch 30: loss improved from 0.66320 to 0.66208, saving model to /content/drive/MyDrive/nerve_segmentation/U-Net/models/my_model2.hdf5\n",
            "26/26 [==============================] - 41s 2s/step - loss: 0.6621 - accuracy: 0.9190 - dice_coef: 0.1386 - jacard: 0.0745 - auc_7: 0.5000 - mean_io_u_7: 0.4595 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 0.6616 - val_accuracy: 0.9188 - val_dice_coef: 0.1388 - val_jacard: 0.0746 - val_auc_7: 0.5000 - val_mean_io_u_7: 0.4594 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-e5e6484cf365>:47: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  results = model.predict_generator(test_generator_2,verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 3s 143ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/0.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/1.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/2.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/3.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/4.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/5.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/6.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/7.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/8.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/9.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/10.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/11.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/12.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/13.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/14.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/15.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/16.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/17.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/18.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-59-240b4496da9c>:6: UserWarning: /content/nerve_segmentation/tmp_result/19.png is a low contrast image\n",
            "  io.imsave(os.path.join(save_path,\"%d.png\"%(i)),img)\n",
            "WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/0.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/1.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/10.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/11.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/12.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/13.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/14.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/15.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/16.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/17.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/18.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/19.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/2.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/3.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/4.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/5.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/6.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/7.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/8.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-11-7b2900d936ec>:6: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/9.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + file, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/0.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/1.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/10.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/11.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/12.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/13.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/14.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/15.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/16.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/17.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/18.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/19.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropping is done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/2.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/3.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/4.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/5.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/6.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/7.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/8.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-13-a26a2ee73cd2>:5: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/my_model2/9.png is a low contrast image\n",
            "  io.imsave(folder + '/' + img, tmp)\n",
            "<ipython-input-14-076a0b31c788>:7: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/1.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+1) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/10.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/19.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:16: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/2.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:19: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/20.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+8) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/3.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/4.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/5.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/6.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/7.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/8.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:13: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/9.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])-10) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/11.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/12.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/13.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/14.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/15.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/16.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/17.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n",
            "<ipython-input-14-076a0b31c788>:10: UserWarning: /content/drive/MyDrive/nerve_segmentation/U-Net/test_results/download/18.png is a low contrast image\n",
            "  io.imsave(output_folder + '/' + str(int(img.split('.')[0])+9) + '.png', tmp)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = res[0]*255\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8FqezCgWRLS",
        "outputId": "0784bdfc-fc66-4292-efc0-c8d6fa27e73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]],\n",
              "\n",
              "       [[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aDRbHdULf0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527a7abb-2b45-43b6-bc10-5026accae0d3"
      },
      "source": [
        "log_file = open(LOG_PATH + \"/log_\" + SAVE_NAME + \".pkl\" , \"rb\")\n",
        "output = pickle.load(log_file)\n",
        "i = 0\n",
        "for key, value in output.items():\n",
        "  print(key + \" --> \" + str(value[EPOCH-1]))\n",
        "  i = i+1\n",
        "print(50*\"-\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss --> 0.25439178943634033\n",
            "accuracy --> 0.9175898432731628\n",
            "dice_coef --> 0.1351488083600998\n",
            "jacard --> 0.07252132892608643\n",
            "auc_1 --> 0.7009954452514648\n",
            "mean_io_u_1 --> 0.4587949216365814\n",
            "precision_1 --> 0.0\n",
            "recall_1 --> 0.0\n",
            "val_loss --> 0.27388301491737366\n",
            "val_accuracy --> 0.9194892644882202\n",
            "val_dice_coef --> 0.1702936291694641\n",
            "val_jacard --> 0.0930793285369873\n",
            "val_auc_1 --> 0.7165288329124451\n",
            "val_mean_io_u_1 --> 0.4597446322441101\n",
            "val_precision_1 --> 0.0\n",
            "val_recall_1 --> 0.0\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX4aZoLJeGZ1"
      },
      "source": [
        "mean_dice_coef = mean_dice(TEST_PATH +   '/labels', \n",
        "                           RESULT_PATH + '/download')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U6Z9QBnePTW"
      },
      "source": [
        "mean_dice_coef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fif9u0rLgn4j"
      },
      "source": [
        "## Train with Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq9yvL9RgpNk"
      },
      "source": [
        "def train_eval_drive(save_name, initial_model_name, n_samples, train_batch = 3, test_batch = 3, epochs = 5):\n",
        "  \n",
        "  shutil.rmtree(TMP_TRAIN, ignore_errors=False, onerror=None)\n",
        "  os.mkdir(TMP_TRAIN)\n",
        "  os.mkdir(TMP_TRAIN + \"/images\")\n",
        "  os.mkdir(TMP_TRAIN + \"/labels\")\n",
        "\n",
        "  shutil.rmtree(TMP_TEST, ignore_errors=False, onerror=None)\n",
        "  os.mkdir(TMP_TEST)\n",
        "  os.mkdir(TMP_TEST + \"/images\")\n",
        "  os.mkdir(TMP_TEST + \"/labels\")\n",
        "  \n",
        "  pad(TRAIN_PATH + '/images', TMP_TRAIN + '/images')\n",
        "  pad(TRAIN_PATH + '/labels', TMP_TRAIN + '/labels')\n",
        "\n",
        "  pad(TEST_PATH + '/images', TMP_TEST + '/images')\n",
        "  pad(TEST_PATH + '/labels', TMP_TEST + '/labels')\n",
        "  \n",
        "  data_gen_args = dict()\n",
        "  train_generator = trainGenerator(train_batch, TMP_TRAIN, 'images', 'labels', data_gen_args, save_to_dir = None, target_size=(608,576))\n",
        "  test_generator = testGenerator2(test_batch, TMP_TEST, 'images', 'labels', data_gen_args, save_to_dir = None, target_size=(608,576))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "  \n",
        "    model = unet(input_size=(608,576,1))\n",
        "    if epoch != 0:\n",
        "      model.load_weights(f'{MODEL_PATH}/{save_name +\"_\"+ str(epoch-1)}.hdf5')\n",
        "    else:\n",
        "      if initial_model_name != None:\n",
        "        model.load_weights(f'{MODEL_PATH}/{initial_model_name}.hdf5')\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(MODEL_PATH + \"/\" + save_name + \"_\" + str(epoch) +\".hdf5\", monitor='loss',verbose=1, save_best_only=True)\n",
        "\n",
        "    model_history = model.fit_generator(train_generator, steps_per_epoch=n_samples//train_batch, epochs=1, callbacks=[model_checkpoint],\n",
        "                                      validation_data=test_generator, validation_steps=20//test_batch)\n",
        "  \n",
        "    log_file = open(LOG_PATH + \"/log_{}.pkl\".format(save_name + str(epoch)), \"wb\")#history file\n",
        "    pickle.dump(model_history.history, log_file)\n",
        "    log_file.close()\n",
        "\n",
        "    test_generator_2 = testGenerator(TMP_TEST, target_size=(608,576))\n",
        "    results = model.predict_generator(test_generator_2,verbose=1)\n",
        "\n",
        "    shutil.rmtree(TMP_RESULT, ignore_errors=False, onerror=None)\n",
        "    os.mkdir(TMP_RESULT)\n",
        "    saveResult_drive(TMP_RESULT, results)\n",
        "    \n",
        "    os.mkdir(RESULT_PATH + '/' + save_name + str(epoch))\n",
        "    crop(TMP_RESULT, RESULT_PATH + '/' + save_name + str(epoch))\n",
        "\n",
        "    threshold(RESULT_PATH + '/' + save_name + str(epoch))\n",
        "\n",
        "    os.mkdir(RESULT_PATH + '/download' + \"_\"+save_name + str(epoch))\n",
        "    set_order(RESULT_PATH + '/' + save_name + str(epoch), RESULT_PATH + '/download' + \"_\"+save_name + str(epoch))\n",
        "\n",
        "    mean_dice_coef = mean_dice(TEST_PATH   + '/labels', \n",
        "                               RESULT_PATH + '/download_' + save_name + str(epoch))\n",
        "    print(f\"\\nMean dice coeff at epoch {epoch}: {mean_dice_coef}\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_f5Sa6ii1FO"
      },
      "source": [
        "train_sample_number = len(os.listdir(TRAIN_PATH + '/images'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS_ZE_bssBkB"
      },
      "source": [
        "SAVE_NAME = 'my_model'\n",
        "initial_model_name = None\n",
        "\n",
        "train_eval_drive(save_name=SAVE_NAME, initial_model_name = initial_model_name, n_samples= train_sample_number, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41uZa_HUESxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359eaafe-e1bd-426d-d2b7-75411c5e2671"
      },
      "source": [
        "!git clone https://github.com/nikhilroxtomar/Retina-Blood-Vessel-Segmentation-in-PyTorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Retina-Blood-Vessel-Segmentation-in-PyTorch'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 105 (delta 17), reused 98 (delta 16), pack-reused 1\u001b[K\n",
            "Receiving objects: 100% (105/105), 8.87 MiB | 6.64 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Retina-Blood-Vessel-Segmentation-in-PyTorch/UNET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MIRwiozgTBz",
        "outputId": "8210c546-2ef4-4ec7-9f7b-a186a724fe50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Retina-Blood-Vessel-Segmentation-in-PyTorch/UNET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FI_IladheJj",
        "outputId": "1568ebf7-5904-4ca2-a990-f9f664e2e682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.py  img\t  model.py  __pycache__  results  train.py\n",
            "files\t loss.py  new_data  README.md\t test.py  utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8e2UJ8Vhggr",
        "outputId": "dfe97a75-0b0f-42dc-8fb9-07e14c65453e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 20/20 [00:10<00:00,  1.97it/s]\n",
            "Jaccard: 0.6634 - F1: 0.7974 - Recall: 0.7771 - Precision: 0.8240 - Acc: 0.9657\n",
            "FPS:  12.45600955188492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CObhDpu0rrA3",
        "outputId": "9c37958d-1f62-464f-c31e-ef415304ab89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 20/20 [00:10<00:00,  1.95it/s]\n",
            "Jaccard: 0.6634 - F1: 0.7974 - Recall: 0.7769 - Precision: 0.8245 - Acc: 0.9657\n",
            "FPS:  12.646520838185864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MV7tLsHhldJ",
        "outputId": "21d560e9-fe70-4920-b561-743e47eda50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Size:\n",
            "Train: 80 - Valid: 20\n",
            "\n",
            "Valid loss improved from inf to 1.3519. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 01 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 1.168\n",
            "\t Val. Loss: 1.352\n",
            "\n",
            "Valid loss improved from 1.3519 to 0.9793. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 02 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.983\n",
            "\t Val. Loss: 0.979\n",
            "\n",
            "Valid loss improved from 0.9793 to 0.8961. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 03 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.923\n",
            "\t Val. Loss: 0.896\n",
            "\n",
            "Valid loss improved from 0.8961 to 0.8537. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 04 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.877\n",
            "\t Val. Loss: 0.854\n",
            "\n",
            "Valid loss improved from 0.8537 to 0.8122. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 05 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.835\n",
            "\t Val. Loss: 0.812\n",
            "\n",
            "Valid loss improved from 0.8122 to 0.7698. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 06 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.795\n",
            "\t Val. Loss: 0.770\n",
            "\n",
            "Valid loss improved from 0.7698 to 0.7413. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 07 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.759\n",
            "\t Val. Loss: 0.741\n",
            "\n",
            "Valid loss improved from 0.7413 to 0.7163. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 08 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.726\n",
            "\t Val. Loss: 0.716\n",
            "\n",
            "Valid loss improved from 0.7163 to 0.6765. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 09 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.695\n",
            "\t Val. Loss: 0.676\n",
            "\n",
            "Valid loss improved from 0.6765 to 0.6541. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 10 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.665\n",
            "\t Val. Loss: 0.654\n",
            "\n",
            "Valid loss improved from 0.6541 to 0.6263. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 11 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.637\n",
            "\t Val. Loss: 0.626\n",
            "\n",
            "Valid loss improved from 0.6263 to 0.6088. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 12 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.611\n",
            "\t Val. Loss: 0.609\n",
            "\n",
            "Valid loss improved from 0.6088 to 0.5831. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 13 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.588\n",
            "\t Val. Loss: 0.583\n",
            "\n",
            "Valid loss improved from 0.5831 to 0.5676. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 14 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.567\n",
            "\t Val. Loss: 0.568\n",
            "\n",
            "Valid loss improved from 0.5676 to 0.5445. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 15 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.546\n",
            "\t Val. Loss: 0.545\n",
            "\n",
            "Valid loss improved from 0.5445 to 0.5301. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 16 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.527\n",
            "\t Val. Loss: 0.530\n",
            "\n",
            "Valid loss improved from 0.5301 to 0.5089. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 17 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.508\n",
            "\t Val. Loss: 0.509\n",
            "\n",
            "Valid loss improved from 0.5089 to 0.4953. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 18 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.492\n",
            "\t Val. Loss: 0.495\n",
            "\n",
            "Valid loss improved from 0.4953 to 0.4890. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 19 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.478\n",
            "\t Val. Loss: 0.489\n",
            "\n",
            "Valid loss improved from 0.4890 to 0.4750. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 20 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.463\n",
            "\t Val. Loss: 0.475\n",
            "\n",
            "Valid loss improved from 0.4750 to 0.4621. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 21 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.447\n",
            "\t Val. Loss: 0.462\n",
            "\n",
            "Valid loss improved from 0.4621 to 0.4537. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 22 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.435\n",
            "\t Val. Loss: 0.454\n",
            "\n",
            "Valid loss improved from 0.4537 to 0.4491. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 23 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.422\n",
            "\t Val. Loss: 0.449\n",
            "\n",
            "Valid loss improved from 0.4491 to 0.4441. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 24 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.411\n",
            "\t Val. Loss: 0.444\n",
            "\n",
            "Valid loss improved from 0.4441 to 0.4310. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 25 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.399\n",
            "\t Val. Loss: 0.431\n",
            "\n",
            "Valid loss improved from 0.4310 to 0.4251. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 26 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.387\n",
            "\t Val. Loss: 0.425\n",
            "\n",
            "Valid loss improved from 0.4251 to 0.4248. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 27 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.379\n",
            "\t Val. Loss: 0.425\n",
            "\n",
            "Valid loss improved from 0.4248 to 0.4124. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 28 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.367\n",
            "\t Val. Loss: 0.412\n",
            "\n",
            "Valid loss improved from 0.4124 to 0.4073. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 29 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.354\n",
            "\t Val. Loss: 0.407\n",
            "\n",
            "Epoch: 30 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.343\n",
            "\t Val. Loss: 0.418\n",
            "\n",
            "Epoch: 31 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.334\n",
            "\t Val. Loss: 0.415\n",
            "\n",
            "Valid loss improved from 0.4073 to 0.4061. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 32 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.323\n",
            "\t Val. Loss: 0.406\n",
            "\n",
            "Valid loss improved from 0.4061 to 0.4031. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 33 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.314\n",
            "\t Val. Loss: 0.403\n",
            "\n",
            "Epoch: 34 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.305\n",
            "\t Val. Loss: 0.409\n",
            "\n",
            "Valid loss improved from 0.4031 to 0.3960. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 35 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.294\n",
            "\t Val. Loss: 0.396\n",
            "\n",
            "Epoch: 36 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.286\n",
            "\t Val. Loss: 0.399\n",
            "\n",
            "Valid loss improved from 0.3960 to 0.3942. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 37 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.278\n",
            "\t Val. Loss: 0.394\n",
            "\n",
            "Valid loss improved from 0.3942 to 0.3940. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 38 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.272\n",
            "\t Val. Loss: 0.394\n",
            "\n",
            "Epoch: 39 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.266\n",
            "\t Val. Loss: 0.400\n",
            "\n",
            "Valid loss improved from 0.3940 to 0.3895. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 40 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.261\n",
            "\t Val. Loss: 0.389\n",
            "\n",
            "Epoch: 41 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.255\n",
            "\t Val. Loss: 0.390\n",
            "\n",
            "Epoch: 42 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.247\n",
            "\t Val. Loss: 0.390\n",
            "\n",
            "Valid loss improved from 0.3895 to 0.3841. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 43 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.243\n",
            "\t Val. Loss: 0.384\n",
            "\n",
            "Epoch: 44 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.240\n",
            "\t Val. Loss: 0.386\n",
            "\n",
            "Epoch: 45 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.236\n",
            "\t Val. Loss: 0.385\n",
            "\n",
            "Epoch: 46 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.233\n",
            "\t Val. Loss: 0.385\n",
            "\n",
            "Epoch: 47 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.227\n",
            "\t Val. Loss: 0.385\n",
            "\n",
            "Valid loss improved from 0.3841 to 0.3823. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 48 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.223\n",
            "\t Val. Loss: 0.382\n",
            "\n",
            "Epoch: 49 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.220\n",
            "\t Val. Loss: 0.387\n",
            "\n",
            "Epoch: 50 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.219\n",
            "\t Val. Loss: 0.386\n",
            "\n",
            "Valid loss improved from 0.3823 to 0.3785. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 51 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.216\n",
            "\t Val. Loss: 0.379\n",
            "\n",
            "Valid loss improved from 0.3785 to 0.3775. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 52 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.214\n",
            "\t Val. Loss: 0.377\n",
            "\n",
            "Epoch: 53 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.210\n",
            "\t Val. Loss: 0.379\n",
            "\n",
            "Valid loss improved from 0.3775 to 0.3762. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 54 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.209\n",
            "\t Val. Loss: 0.376\n",
            "\n",
            "Epoch: 55 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.206\n",
            "\t Val. Loss: 0.378\n",
            "\n",
            "Epoch: 56 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.204\n",
            "\t Val. Loss: 0.378\n",
            "\n",
            "Epoch: 57 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.202\n",
            "\t Val. Loss: 0.377\n",
            "\n",
            "Epoch: 58 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.200\n",
            "\t Val. Loss: 0.377\n",
            "\n",
            "Epoch: 59 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.199\n",
            "\t Val. Loss: 0.380\n",
            "\n",
            "Epoch: 60 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.197\n",
            "\t Val. Loss: 0.380\n",
            "\n",
            "Epoch: 61 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.195\n",
            "\t Val. Loss: 0.380\n",
            "\n",
            "Valid loss improved from 0.3762 to 0.3759. Saving checkpoint: /content/drive/MyDrive/nerve_segmentation/checkpoint_new.pth\n",
            "Epoch: 62 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.194\n",
            "\t Val. Loss: 0.376\n",
            "\n",
            "Epoch: 63 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.193\n",
            "\t Val. Loss: 0.376\n",
            "\n",
            "Epoch: 64 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.192\n",
            "\t Val. Loss: 0.382\n",
            "\n",
            "Epoch: 65 | Epoch Time: 0m 33s\n",
            "\tTrain Loss: 0.191\n",
            "\t Val. Loss: 0.379\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Retina-Blood-Vessel-Segmentation-in-PyTorch/UNET/train.py\", line 107, in <module>\n",
            "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
            "  File \"/content/Retina-Blood-Vessel-Segmentation-in-PyTorch/UNET/train.py\", line 28, in train\n",
            "    epoch_loss += loss.item()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O39NGtaWjBAV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}