{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xgFqHrYRPVXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function perform multiple augmentations on the input image like horizontal flip, rotation, brightness and contrast changes, and zoom. It is not a complete solution and you can always add more augmentations to the function as per your requirement."
      ],
      "metadata": {
        "id": "C7ZVH5VXPwyJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf6aDzN-O-EF"
      },
      "outputs": [],
      "source": [
        "def augment_retinal_image(image):\n",
        "    # Randomly flipping the image horizontally\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = cv2.flip(image, 1)\n",
        "        \n",
        "    # Randomly rotating the image by a small angle\n",
        "    angle = np.random.randint(-5, 5)\n",
        "    M = cv2.getRotationMatrix2D((image.shape[1]/2, image.shape[0]/2), angle, 1)\n",
        "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
        "    \n",
        "    # Randomly applying brightness and contrast changes\n",
        "    alpha = np.random.uniform(0.5, 1.5)\n",
        "    image = cv2.convertScaleAbs(image, alpha=alpha, beta=np.random.randint(-50, 50))\n",
        "\n",
        "    # Randomly zooming the image\n",
        "    zoom = np.random.uniform(0.9, 1.1)\n",
        "    M = cv2.getRotationMatrix2D((image.shape[1]/2, image.shape[0]/2), 0, zoom)\n",
        "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(parent_dir, augment_fn=None):\n",
        "    # Create a list of all subdirectories within the parent directory\n",
        "    subdirs = [d for d in tf.io.gfile.listdir(parent_dir) if tf.io.gfile.isdir(f\"{parent_dir}/{d}\")]\n",
        "    \n",
        "    # Create a dataset of all image paths within the subdirectories\n",
        "    image_paths = []\n",
        "    for subdir in subdirs:\n",
        "        image_paths += tf.io.gfile.glob(f\"{parent_dir}/{subdir}/*.jpg\")\n",
        "    images_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    \n",
        "    # Read and decode the images\n",
        "    def read_and_decode(path):\n",
        "        image = tf.io.read_file(path)\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        if augment_fn:\n",
        "            image = augment_fn(image)\n",
        "        return image\n",
        "    images_ds = images_ds.map(read_and_decode, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    return images_ds"
      ],
      "metadata": {
        "id": "9OAY-aoPPeVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes two arguments, the path of the parent directory and an optional function for data augmentation. It first creates a list of all subdirectories within the parent directory, it then creates a dataset of all image paths within the subdirectories. It then uses the tf.data.Dataset.map() method to read and decode the images, applying the optional data augmentation function, if provided, before returning the dataset."
      ],
      "metadata": {
        "id": "Er1wLST_PqMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augment_fn = lambda x: augment_retinal_image(x)\n",
        "images_ds = create_dataset(\"path/to/parent/dir\", augment_fn)"
      ],
      "metadata": {
        "id": "zj7d1CkJPijo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}